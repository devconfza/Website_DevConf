---
layout: default
---

<div class="content">
    <h1>Background on DevConf 2022 Review Process</h1>
    <p>
        This page is a retrospective guide on how the talks were selected for the next DevConf conference and hope it
        helps the community transparency of the process and secondary goal to help others prepare for submissions for
        other
        events and DevConf in the future. This is the communities event and as the organisers, we welcome all feedback and
        improvements for how we can be better
        stewards of the communities event. Please feel free to email us at <a
            href="mailto:info@devconf.co.za">info@devconf.co.za</a>
        about this or anything else about your event.
    </p>
    <p>
        We made use of the <a href="https://sessionize.com/" target="_blank" rel="noopener noreferrer">sessionize
            platform</a> to collect, review
        and respond to talks. The <a href="https://sessionize.com/devconf2022" target="_blank"
            rel="noopener noreferrer">call for speakers</a>
        page is still available with all the information on it about how the process would be run. Sessionize has a free
        test which you can log in to, get 10 fake submissions and go through reviewing and ranking them if you would
        like to
        see exactly what we used.
    </p>
    <p>
        It is important to note that DevConf uses an anonymous review process. All any of the reviewers see is the
        title, notes,
        description and track. If it is not in those fields it
        is not part of the information reviewers use.
    </p>
    <p>
        We are using the team rank explicitly here as the talks were not scored or assigned a rating. They were ranked,
        i.e. first, second, third etc....
    </p>
    <p>
        The ranking is based on the Elo rating system, a chess-rating system also used for multiplayer competitions in a
        number of video games, sports, board games etc. You can read more about it on <a
            href="https://en.wikipedia.org/wiki/Elo_rating_system" target="_blank"
            rel="noopener noreferrer"></a>Wikipedia</a>.<br />

        In the beginning, each session gets a 1500 rating.<br />

        A comparison starts with choosing a triple that will be compared. The first batch of triplets is chosen randomly
        until all sessions are compared at least once. Then things get smarter. Sessionize looks at comparison count,
        win count
        and rating difference to pick the next triplet while making sure that the reviewers never compare the same
        sessions twice.<br />

        Each comparison results in three 'games': A vs B, B vs C and C vs A. The result of each game can be a win, lose
        or draw. Each result changes the session's rating. The exact amount depends on the other session's current
        rating (as
        defined by Elo ranking system). Our K-factor ranges from 40 at the start to 10 towards the end of the
        evaluation.
    </p>
    <p>
        Talks were anonymously ranked in Sessionize by a panel of 9 reviewers from diverse backgrounds of race,
        gender, age, experience, technology and disabilities. Each reviewer was either a previous speaker or reviewer of
        DevConf
        and thus has had a deep insight into what conference goals are and the type of event it should be. We did not
        provide any official guidance or "marking guide" for reviewers - rather we trusted them to bring their
        experience to the selection.<br />
        Reviewers could provide feedback, but few did and even those who did provide feedback, did so sparingly. All the
        reviewers did this in their
        free time without any promise of compensation and spent tens of hours working on it so we do not require them to
        add comments to their reviews.<br />
        The average of the rankings assigned by the Elo score is then used to determine the final ranking.
    </p>
    <p>
        Once that that was done, Candice and Robert build the agenda mostly from the ordered list (i.e. talks ranked 1
        through 40 go in), with a few exceptions:
    <ul>
        <li>International speakers - Due to the risks for logistics and travel, we did not accept any international
            speakers. We hope to bring international speakers back in 2023. This was decided before the call for
            speakers, and communicated on the call for speakers website.</li>
        <li>A speaker with a selected talk would have all their other submissions dropped. This is to allow many diverse
            views and opportunities (one speaker sharing twice in a day vs. 2 speakers sharing once in a day) and
            allow speakers to spend time on the day with the audience and enjoy the event as well as to give them
            time to focus.</li>
        <li>Duplication - If we already have a talk that covers the same ground, we won't select a second one. We
            will have talks on the same topic but in different aspects of those. </li>
        <li>Content that doesn't fit - We published a list of what is good and bad as part of the submission request
            and thankfully the ranking pushes these down so we have not had to drop any highly ranked inappropriate
            talks but that is a possibility.</li>
        <li>Discretionary - As organisers, we need to ensure a balanced and relevant agenda, based entirely on
            community feedback provided over the years so that the conference continues to be a high-quality event.
            We apply discretion only to ensure our agenda suits our audiences varying interests. We are guided by
            our reviewer feedback, community feedback on social media and at meetups and other conferences and this
            discretion is applied exceptionally sparingly. <br />
            A good example from this year is we had 2 similar talks in our top 20 in the 2021 reviews; the first talk
            was, in
            fact, the #1 ranked talk and was from an international speaker, the other was from a local speaker. We
            opted for the lower-ranked one as the local speaker has a better opportunity to understand our market
            (which was relevant to the talk) and we felt they could do as good a performance.</li>
        <li>Where there are similar talks that rank similarly, we would allow the opportunity to underrepresented
            groups.</li>
        <li>We also try to limit too much content in a particular theme - considering most of our submissions are
            about languages and tools, and many ranked in the top 12 but we limited those talks to make room for
            mental health, DevOps and Security, for example.</li>
    </ul>
    </p>
    <p>
    <h2>FAQ</h2>
    <h3>How many talks are there?</h3>
    We select 29 talks from 217 submissions, meaning that only 13% of talks get selected.
    <!-- <h3>Does being International help?</h3>
    No. We believe the community in South Africa is amazing and brings a unique and powerful understanding that
    international speakers do not have and while for 2020 we used all our international budget that is not a promise
    as seen in 2019 when the community did not rank international talks high enough for selection so we did not use
    all the budget. -->
    <h3>What can I do to increase my chances for selection in future?</h3>
    Write a great description. Your description needs to do a lot of work for you:
    <ul>
        <li>It needs to provide the detail of the content you are going to present potentially to a reviewer who
            isn't specifically an expert in it.</li>
        <li>It needs to show you know what you are talking about.</li>
        <li>It needs to have something to help it stand out. </li>

    </ul>
    This is difficult to do and talks a lot of writing and polishing to get it perfect. Attending the CFP
    workshops during the year that is run by the community is a very useful way to skill up here and this is why we
    partnered with other communities to run these for DevConf especially.
    A second tip is to engage in the community throughout the year - if you have an important topic, helping
    reviewers to know it is valuable ahead of conference time is invaluable.
    <h3>Does being a speaker from a current or previous sponsor help?</h3>
    Not at all. The process is anonymous so there is no way it can impact it. In addition, your event is run totally
    cost neutral with no profit being taken by the organisers so monatry influence is not possible.
    <h3>Why did the rejection emails not contain feedback?</h3>
    There are three factors that lead to a basic "sorry, you did not get selected email". <ul>
        <li>Sessionize has no way to automate giving even basic information (like rank for example) let alone
            feedback. </li>
        <li>As stated reviewers did not leave feedback for the majority of talks, so even if there was a solution
            there would be no content.</li>
        <li>It is not possible for Candice and Robert to write personal rejections in a timeframe that is
            respectful of speakers who would wait months for feedback this way.</li>
    </ul>
    </p>
    <h3>Some people have got emails telling them they are accepted, while others have not - is there an issue?</h3>
    No. The process, as documented on the call for speakers, is that once we select the speakers they are given an
    opportunity to confirm. We have had a speaker or two not accept and in that case, we then go back to the submissions
    to get the next person in the ranking. Once we have all the 29 slots filled, then we send out the decline emails.
    <h3>There was not enough space in the description for me to get my talk across properly.</h3>
    <p>We are aware of how limited the space in the description and will be increasing it for future events.</p>
</div>