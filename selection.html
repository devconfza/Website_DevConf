---
layout: default
---

<div class="content">
    <h1>Background on DevConf 2024 Review Process</h1>
    <p>
    <p>
        We are excited to share with you how we selected the talks for the upcoming DevConf conference. Our goal is to
        be transparent and inclusive of our community, and to help you prepare for future submissions to DevConf and
        other events. We value your feedback and suggestions on how we can improve our event for you. Please email us at
        <a href="mailto:info@devconf.co.za">info@devconf.co.za</a> with any questions or comments.
    </p>
    <p>
        We used the <a href="https://sessionize.com/" target="_blank" rel="noopener noreferrer">Sessionize platform</a>
        to manage the talk submissions. You can still see the <a href="https://sessionize.com/devconf-2024"
            target="_blank" rel="noopener noreferrer">call for speakers page</a> with all the details on our process. We
        use the <a href="https://sessionize.com/playbook/evaluation-modes-explained#comparison-evaluation-mode-2"
            target="_blank" rel="noopener noreferrer">Comparison evaluation mode</a> to compare and rank the talks.

        You can also try a free simulation on sessionize with 10 sample submissions to review and rank if you want to
        experience what we did.

    <p>
        We want to let you know that DevConf uses an anonymous review process. The reviewers only see the title, notes,
        description and track of each submission. Any other information you provide is hidden from them. Even we, as
        organisers, can’t see any extra information or personal details until the review process is over.
    </p>

    <p>
        We are grateful to our panel of 21 reviewers who ranked the talks for DevConf 2024 in Sessionize. They come from
        diverse backgrounds of race, gender, age, experience, technology and abilities. They are all previous
        speakers and/or reviewers of DevConf and have a deep understanding of our conference’s vision and values. We did not
        give them any specific criteria nor instructions - we trusted them to use their expertise and judgment to select
        the best talks. Reviewers had the option to provide written feedback on a submission, but most did not. We
        understand that they did this work voluntarily and generously in their spare time without any compensation. We
        appreciate their time and effort in reviewing the talks. The final ranking was determined by the average of the
        Elo scores assigned by the reviewers. The total time spent on reviewing talks was 35 515 minutes.
    </p>
    <p>
        Once that that was done, Candice and Robert, who are the organisers of the event, built the agenda mostly from
        the ordered list (i.e. talks ranked 1
        through 40 go in), with a few exceptions:
    <ul>
        <li>International speakers - Due to cost constraints, once the budget for international speakers is reached, all
            other international speakers are declined.</li>
        <li>A speaker with a selected talk would have all their other submissions dropped. This is to allow many diverse
            views and opportunities (one speaker sharing twice in a day vs. 2 speakers sharing once in a day). It also allows speakers to enjoy the event, spend time with the audience, and have time to focus if they need it.</li>
        <li>Duplication - If we already have a talk that covers the same ground, we won't select a second one. We
            could have talks on the same topic if it's clear that there is distinction and value for the audience. </li>
        <li>Content that doesn't fit - We published a list of what is and isn't suitable content on the submissions platform, but naturally the aggregate of reviewer rankings push these down so we have not had to drop any highly ranked inappropriate
            talks (but this is a possibility).</li>
        <li>Discretionary - As organisers, we need to ensure a balanced and relevant agenda, based entirely on
            community feedback provided over the years so that the conference continues to be a high-quality event.
            We apply discretion only to ensure our agenda suits our audience's varying interests. We are guided by feedback from reviewers as well as community via social media, meetups and other conferences. We apply discretion exceptionally sparingly. <br />
            A good example: In 2021, we had 2 similar talks ranked in the top 20; the first talk
            was, in
            fact, the #1 ranked talk and was from an international speaker, while the other was from a local speaker. We
            opted for the lower-ranked one as the local speaker had the advantage of relevance in our market
            (which was pertinant to the talk) and we were confident they would present and capture their audience just
            as well as the international speaker.</li>
        <li>Where there are similar talks that rank similarly, we would allow the opportunity to underrepresented groups.</li>
        <li>We also try to limit too much content in a particular theme. Considering most of our submissions are
            about languages and tools, most of the top rated talks are in the same  category. In the interest of having a varied agenda, we have to exclude some of the better rated talks to make room for different subjects such as mental health, DevOps and Security.</li>
    </ul>
    </p>
    <p>
    <h2>FAQ</h2>
    <h3>How many talks are there?</h3>
    We selected 29 talks from 622 submissions, meaning that only 4% of talks submitted were included in the agenda.
    <h3>Does being International help?</h3>
    No. We believe the community in South Africa is amazing and brings a unique and powerful understanding that
    international speakers do not always have. Every year, DevConf sets aside a budget for international speakers ahead of reviewing talks. This includes travel, accommodation and most meals. Sometimes the budget is fully allocated, and sometimes it isn't (e.g. in 2019 when the community did not rank international talks highly enough for selection).
    <h3>What can I do to increase my chances for selection in future?</h3>
    Write a great description. Your description needs to do a lot of work for you:
    <ul>
        <li>It needs to provide the detail of the content you are going to present potentially to a reviewer who isn't necessarily an expert in the subject.</li>
        <li>It needs to be clear you know what you are talking about.</li>
        <li>It needs to stand out in some uniquely valuable way so that a reviewer would prefer it over the large majority of other talk submissions.</li>

    </ul>
    Of course, this is difficult to do and stand-out talk submissions require a lot of writing, rewriting and polishing. Attending the CFP
    workshops during the year that are run by the community is a very useful way to skill up here and this is why we have on occassions 
    partnered with other communities to run these for DevConf. In 2019, three of the workshop attendees were selected to speak, and all were first time speakers!
    A second tip is to engage in the community throughout the year - if you have an important topic, helping
    reviewers to know it is valuable ahead of conference time is invaluable.
    <h3>Does being a speaker from a current or previous sponsor help?</h3>
    Not for selection, no. Past experience might help with a good submission though. It's important to note that the author of a submission is not relevant to reviewers. The process is anonymous and reviewers are therefore not influenced by anyone's identity, age, employer, etc. In addition, our event is run totally
    cost neutral with no profit being taken by the organisers so monetry influence is not possible.
    <h3>Why did the rejection emails not contain feedback?</h3>
    There are three factors that lead to a basic "sorry, you did not get selected email". <ul>
        <li>Sessionize has no way to automate giving even basic information (like rank for example) let alone qualitative
            feedback. </li>
        <li>As stated reviewers did not leave feedback for the majority of talks, so even if there was a solution
            there would be no content.</li>
        <li>It is not possible for Candice and Robert to write hundreds of personal rejections in a timeframe that is
            respectful of speakers who would wait months for feedback this way.</li>
    </ul>
    </p>
</div>