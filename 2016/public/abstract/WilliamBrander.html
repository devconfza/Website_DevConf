	<p>We all have a favourite actor. For some of us it's a heavy hitter like Robert Downey Jr, for others: the more obscure the actor the better. Regardless of how good the actor is though, he or she can only act out one scene at a time. The same is true for systems that implement the Actor Model - a conceptual model aimed at reducing the complexity associated with concurrency. By treating a piece of computation as an "actor" we can direct multiple actors into a single, fluid scene that describes complex business scenarios in a simple fashion all while make sure each actor only has to do one thing at a time. Join William as he sets the scene for explaining the Actor Model, and tries to fit as many bad actor puns into one talk as he can.</p>
